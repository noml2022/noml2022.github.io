---
layout: post
title: About
usemathjax: true
---

### About

The first Chinese-Russian Conference on Numerical Optimization and Machine Learning (NOML 2022) will be hold online, from July 11 to July 14, 2022. This conference is organized by the School of Mathematical Science of Beihang University, Beihang International Center for Mathematical Research, Laboratory of Computational Intelligence of Skoltech, and Center for Artificial Intelligence Technology of Skoltech.

The main aim of this conference is to bring together Russian and Chinese researchers actively working on numerical optimization and machine learning to exchange ideas, views, and new results and to build up contacts for future cooperation. All areas of numerical optimization and machine learning are of interest at NOML 2022. These include, but are not limited to:

1. Algorithms and theory in nonlinear optimization
2. Numerical methods for tensor computing
3. Machine learning
4. Mathematical foundations in artificial intelligence

This conference is sponsored by National Natural Science Foundation of China.

---

### Time

Moscow time: 10:00-13:00, Beijing time: 15:00-18:00

---

### Location

Online [Tencent (VooV) meeting](https://voovmeeting.com/user-center/join) room: **625 4141 9475**

Offline location: E404 Main Building, Shahe Campus, Beihang University

---

### Organizational Committee

Deren Han (Beihang University)

Ivan Oseledets (Skoltech)

---

### Hosts

School of Mathematical Science, Beihang University

Beihang International Center for Mathematical Research

Laboratory of Computational Intelligence, Skoltech

Center for Artificial Intelligence Technology, Skoltech

---

### Contact

Chunfeng Cui: chunfengcui at buaa.edu.cn

Talgat Daulbaev: talgat.daulbaev at skoltech.ru, @Daulbaev in telegram

Bo Huang: bohuang0407 at buaa.edu.cn

---

### Materials

Videos: [yandex disk](https://disk.yandex.ru/d/r8NkJJzxCWt4Qg?ncrnd=5056)

---

### Schedule

#### Monday (July, 11)

<table>
<colgroup>
<col width="10%" />
<col width="10%" />
<col width="50%" />
<col width="30%" />
</colgroup>
<thead>
  <tr>
    <th style="text-align:center">Moscow</th>
    <th>Beijing</th>
    <th>Title</th>
    <th>Speaker</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td></td>
    <td></td>
    <td colspan="2"><b>Session 1</b><br>Chair: Deren Han</td>
  </tr>
  <tr>
    <td>10:00-10:10</td>
    <td>15:00-15:10</td>
    <td colspan="2">Opening Ceremony and Group Photo</td>
  </tr>
  <tr>
    <td>10:10-11:00</td>
    <td>15:10-16:00</td>
    <td>Dual Quaternions and Their Applications</td>
    <td>Liqun Qi<br>(The Hongkong Polytechnic University)</td>
  </tr>
  <tr>
    <td>11:00-11:40</td>
    <td>16:00-16:40</td>
    <td>Tensor decompositions and their applications</td>
    <td>Ivan Oseledets<br>(Skoltech)</td>
  </tr>
  <tr>
    <td>11:40-11:50</td>
    <td>16:40-16:50</td>
    <td colspan="2">Break</td>
  </tr>
  <tr>
    <td></td>
    <td></td>
    <td colspan="2"><b>Session 2</b><br>Chair: Ivan Oseledets</td>
  </tr>
  <tr>
    <td>11:50-12:30</td>
    <td>16:50-17:30</td>
    <td>Stochastic Optimization with Heavy-Tailed Noise</td>
    <td>Alexander Gasnikov<br>(MIPT)</td>
  </tr>
  <tr>
    <td>12:30-13:00</td>
    <td>17:30-18:00</td>
    <td>Iteratively reweighted $l_1$ methods for $l_p$ regularization: properties, complexity and acceleration<br></td>
    <td>Hao Wang<br>(ShanghaiTech University)</td>
  </tr>
</tbody>
</table>

#### Tuesday (July, 12)

<table>
<colgroup>
<col width="10%" />
<col width="10%" />
<col width="50%" />
<col width="30%" />
</colgroup>
<thead>
  <tr>
    <th style="text-align:center">Moscow</th>
    <th>Beijing</th>
    <th>Title</th>
    <th>Speaker</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td></td>
    <td></td>
    <td colspan="2"><b>Session 3</b><br>Chair: Talgat Daulbaev</td>
  </tr>
  <tr>
    <td>10:00-10:40</td>
    <td>15:00-15:40</td>
    <td>Tutorial: How to make convex optimization problems differentiable and combine them with neural networks?</td>
    <td>Alexandr Katrutsa<br>(Skoltech)</td>
  </tr>
  <tr>
    <td>10:40-11:10</td>
    <td>15:40-16:10</td>
    <td>Phase retrieval: Theory and Algorithms</td>
    <td>Meng Huang<br>(Beihang University)</td>
  </tr>
  <tr>
    <td>11:10-11:30</td>
    <td>16:10-16:30</td>
    <td colspan="2">Break</td>
  </tr>
  <tr>
    <td></td>
    <td></td>
    <td colspan="2"><b>Session 4</b><br>Chair: Hao Wen</td>
  </tr>
  <tr>
    <td>11:30-12:00</td>
    <td>16:30-17:00</td>
    <td>Understanding the convergence of the preconditioned PDHG method: a view of indefinite proximal ADMM</td>
    <td>Yumin Ma<br>(Nanjing Normal University)</td>
  </tr>
  <tr>
    <td>12:00-12:30</td>
    <td>17:00-17:30</td>
    <td>Dynamic mode decomposition for uncertain data</td>
    <td>Alexandr Katrutsa<br>(Skoltech)</td>
  </tr>
   <tr>
    <td>12:30-13:00</td>
    <td>17:30-18:00</td>
    <td>Constructive Tensor Train with applications</td>
    <td>Gleb Ryzhakov<br>(Skoltech)</td>
  </tr>
</tbody>
</table>

#### Wednesday (July, 13)

<table>
<colgroup>
<col width="10%" />
<col width="10%" />
<col width="50%" />
<col width="30%" />
</colgroup>
<thead>
  <tr>
    <th style="text-align:center">Moscow</th>
    <th>Beijing</th>
    <th>Title</th>
    <th>Speaker</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td></td>
    <td></td>
    <td colspan="2"><b>Session 5</b><br>Chair: Bo Huang</td>
  </tr>
  <tr>
    <td>10:00-10:40</td>
    <td>15:00-15:40</td>
    <td>TTOpt: A Maximum Volume Quantized Tensor Train-based Optimization and its Application to Reinforcement Learning</td>
    <td>Konstantin Sozykin<br>(Skoltech)</td>
  </tr>
  <tr>
    <td>10:40-11:10</td>
    <td>15:40-16:10</td>
    <td>Randomized Douglas-Rachford algorithm for linear systems: Improved accuracy and efficiency</td>
    <td>Jiaxin Xie<br>(Beihang University)</td>
  </tr>
  <tr>
    <td>11:10-11:30</td>
    <td>16:10-16:30</td>
    <td colspan="2">Break</td>
  </tr>
  <tr>
    <td></td>
    <td></td>
    <td colspan="2"><b>Session 6</b><br>Chair: Jiaxin Xie</td>
  </tr>
  <tr>
    <td>11:30-12:00</td>
    <td>16:30-17:00</td>
    <td>Inexact first-order primal-dual methods for a class of saddle point problems</td>
    <td>Zhongming Wu<br>(Nanjing University of Information Science and Technology)</td>
  </tr>
  <tr>
    <td>12:00-12:30</td>
    <td>17:00-17:30</td>
    <td>Sketching and alternating projections for low-rank nonnegative matrix and tensor decompositions</td>
    <td>Sergey Matveev<br>(INM RAS, Moscow)</td>
  </tr>
   <tr>
    <td>12:30-13:00</td>
    <td>17:30-18:00</td>
    <td>Accelerated doubly stochastic gradient method for tensor CP decomposition</td>
    <td>Chunfeng Cui<br>(Beihang University)</td>
  </tr>
</tbody>
</table>

#### Thursday (July, 14)

<table>
<colgroup>
<col width="10%" />
<col width="10%" />
<col width="50%" />
<col width="30%" />
</colgroup>
<thead>
  <tr>
    <th style="text-align:center">Moscow</th>
    <th>Beijing</th>
    <th>Title</th>
    <th>Speaker</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td></td>
    <td></td>
    <td colspan="2"><b>Session 7</b><br>Chair: Meijia Yang</td>
  </tr>
  <tr>
    <td>10:00-10:30</td>
    <td>15:00-15:30</td>
    <td>Tensor-Train Density Estimation</td>
    <td>Georgii Novikov<br>(Skoltech)</td>
  </tr>
  <tr>
    <td>10:30-11:00</td>
    <td>15:30-16:00</td>
    <td>Inertial alternating structure-adapted proximal (-like) gradient method for nonconvex nonsmooth optimization problems</td>
    <td>Xue Gao<br>(Hebei University of Technology)</td>
  </tr>
  <tr>
    <td>11:00-11:20</td>
    <td>16:00-16:20</td>
    <td colspan="2">Break</td>
  </tr>
  <tr>
    <td></td>
    <td></td>
    <td colspan="2"><b>Session 8</b><br>Chair: Chunfeng Cui</td>
  </tr>
  <tr>
    <td>11:20-11:50</td>
    <td>16:20-16:50</td>
    <td>A Double Extrapolation Primal-Dual Algorithm for Saddle Point Problems</td>
    <td>Kai Wang<br>(Nanjing University of Information Science and Technology)</td>
  </tr>
  <tr>
    <td>11:50-12:20</td>
    <td>16:50-17:20</td>
    <td>Task-based parallel programming model for neural networks</td>
    <td>Aleksandr Mikhalev<br>(Skoltech)</td>
  </tr>
   <tr>
    <td>12:20-12:50</td>
    <td>17:20-17:50</td>
    <td>Toward non-quadratic S-lemma and its extension: new theory and application in nonconvex optimization</td>
    <td>Meijia Yang<br>(University of Science and Technology Beijing)</td>
  </tr>
   <tr>
    <td>12:50-13:00</td>
    <td>17:50-18:00</td>
    <td colspan="2">Closing Ceremony and Group Photo</td>
  </tr>
</tbody>
</table>
